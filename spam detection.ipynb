{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMAIL SPAM DETECTION WITH NATURAL LANGUAGE PROCESSING\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:- Narmada Haribhau Ugale\n",
    "Degree:- Computer Science and Engineering\n",
    "College Name:- Shri Guru Gobind Singhji Institute Of Engineering & Technology Nanded   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING SOME REQUIRED LIBRARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading csv file using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Sadanand\\Desktop\\Downloads\\SPAM.csv\",encoding= 'unicode_escape')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type    0\n",
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spam'] = pd.get_dummies(df.type, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ham</td>\n",
       "      <td>What is the plural of the noun research?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ham</td>\n",
       "      <td>Going for dinner.msg you after.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm ok wif it cos i like 2 try new things. But...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>GENT! We are trying to contact you. Last weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wa, ur openin sentence very for</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                               text  spam\n",
       "0     ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1     ham                      Ok lar... Joking wif u oni...     0\n",
       "2    spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3     ham  U dun say so early hor... U c already then say...     0\n",
       "4     ham  Nah I don't think he goes to usf, he lives aro...     0\n",
       "..    ...                                                ...   ...\n",
       "111   ham           What is the plural of the noun research?     0\n",
       "112   ham                    Going for dinner.msg you after.     0\n",
       "113   ham  I'm ok wif it cos i like 2 try new things. But...     0\n",
       "114  spam  GENT! We are trying to contact you. Last weeke...     1\n",
       "115   ham                    Wa, ur openin sentence very for     0\n",
       "\n",
       "[116 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][5]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FreeMsg',\n",
       " 'Hey',\n",
       " 'there',\n",
       " 'darling',\n",
       " \"it's\",\n",
       " 'been',\n",
       " '3',\n",
       " \"week's\",\n",
       " 'now',\n",
       " 'and',\n",
       " 'no',\n",
       " 'word',\n",
       " 'back!',\n",
       " \"I'd\",\n",
       " 'like',\n",
       " 'some',\n",
       " 'fun',\n",
       " 'you',\n",
       " 'up',\n",
       " 'for',\n",
       " 'it',\n",
       " 'still?',\n",
       " 'Tb',\n",
       " 'ok!',\n",
       " 'XxX',\n",
       " 'std',\n",
       " 'chgs',\n",
       " 'to',\n",
       " 'send,',\n",
       " 'Â£1.50',\n",
       " 'to',\n",
       " 'rcv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "df['text']=df['text'].apply(tokenizer)\n",
    "\n",
    "df['text'][5]#after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FreeMsg',\n",
       " 'Hey',\n",
       " 'there',\n",
       " 'darling',\n",
       " \"it's\",\n",
       " 'been',\n",
       " '3',\n",
       " \"week's\",\n",
       " 'now',\n",
       " 'and',\n",
       " 'no',\n",
       " 'word',\n",
       " 'back!',\n",
       " \"I'd\",\n",
       " 'like',\n",
       " 'some',\n",
       " 'fun',\n",
       " 'you',\n",
       " 'up',\n",
       " 'for',\n",
       " 'it',\n",
       " 'still?',\n",
       " 'Tb',\n",
       " 'ok!',\n",
       " 'XxX',\n",
       " 'std',\n",
       " 'chgs',\n",
       " 'to',\n",
       " 'send,',\n",
       " 'Â£1.50',\n",
       " 'to',\n",
       " 'rcv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][5]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freemsg',\n",
       " 'hey',\n",
       " 'there',\n",
       " 'darl',\n",
       " 'it',\n",
       " 'been',\n",
       " '3',\n",
       " 'week',\n",
       " 'now',\n",
       " 'and',\n",
       " 'no',\n",
       " 'word',\n",
       " 'back!',\n",
       " \"i'd\",\n",
       " 'like',\n",
       " 'some',\n",
       " 'fun',\n",
       " 'you',\n",
       " 'up',\n",
       " 'for',\n",
       " 'it',\n",
       " 'still?',\n",
       " 'tb',\n",
       " 'ok!',\n",
       " 'xxx',\n",
       " 'std',\n",
       " 'chgs',\n",
       " 'to',\n",
       " 'send,',\n",
       " 'â£1.50',\n",
       " 'to',\n",
       " 'rcv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sbs = SnowballStemmer(\"english\",ignore_stopwords=False)\n",
    "\n",
    "def stem_it(text):\n",
    "    return [sbs.stem(word) for word in text]\n",
    "\n",
    "df['text'] =df['text'].apply(stem_it)\n",
    "\n",
    "\n",
    "df['text'][5]#after stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)LEMMITIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yeah',\n",
       " 'do!',\n",
       " 'donâ\\x80\\x98t',\n",
       " 'stand',\n",
       " 'to',\n",
       " 'close',\n",
       " 'tho-',\n",
       " 'youâ\\x80\\x98ll',\n",
       " 'catch',\n",
       " 'something!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][90]#before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yeah',\n",
       " 'do!',\n",
       " 'donâ\\x80\\x98t',\n",
       " 'stand',\n",
       " 'to',\n",
       " 'close',\n",
       " 'tho-',\n",
       " 'youâ\\x80\\x98ll',\n",
       " 'catch',\n",
       " 'something!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma =  WordNetLemmatizer()\n",
    "\n",
    "def lemmit_it(text):\n",
    "    return [lemma.lemmatize(word,pos=\"a\") for word in text]\n",
    "\n",
    "df['text']=df['text'].apply(lemmit_it)\n",
    "\n",
    "df['text'][90]#before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) STOP WORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pleas',\n",
       " \"don't\",\n",
       " 'text',\n",
       " 'me',\n",
       " 'anymore.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'noth',\n",
       " 'els',\n",
       " 'to',\n",
       " 'say.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][100]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pleas', 'text', 'anymore.', 'noth', 'els', 'say.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def stop_it(text):\n",
    "    review = [word for word in text if not word in stop_words]\n",
    "    return review\n",
    "df['text']=df['text'].apply(stop_it)\n",
    "\n",
    "df['text'][100]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point,, crazy.., avail, onli, bug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar..., joke, wif, u, oni...]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor..., u, c, alreadi, sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf,, live, around, though]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  [go, jurong, point,, crazy.., avail, onli, bug...     0\n",
       "1   ham                 [ok, lar..., joke, wif, u, oni...]     0\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...     1\n",
       "3   ham  [u, dun, say, earli, hor..., u, c, alreadi, sa...     0\n",
       "4   ham      [nah, think, goe, usf,, live, around, though]     0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "TFV=TfidfVectorizer(analyzer='word',tokenizer=dummy_fun,preprocessor=dummy_fun,token_pattern=None)\n",
    "y=df.spam.values\n",
    "x=TFV.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_text = train_test_split(x,y,random_state=1,test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 74.28571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_log = accuracy_score(y_pred,y_text)*100\n",
    "print(\"accuracy\",acc_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification using LinearSVC \n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(random_state=0) \n",
    "svc.fit(x_train,y_train)\n",
    "y_pred =svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 74.28571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_log = accuracy_score(y_pred,y_text)*100\n",
    "print(\"accuracy\",acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
